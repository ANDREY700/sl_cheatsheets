import streamlit as st

st.header('–§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å, –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏ —á–∏—Å–ª–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è')

st.markdown(
    '''
|| –ó–∞–¥–∞—á–∞ | –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å | –§—É–Ω–∫—Ü–∏—è –≤ üî•PyTorch | –§—É–Ω–∫—Ü–∏—è –ê–∫—Ç–∏–≤–∞—Ü–∏–∏ | –§—É–Ω–∫—Ü–∏—è –≤ üî•PyTorch | –ß–∏—Å–ª–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤ | 
|-|--------|--------|--------|--------|--------|--------|
|1| –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è       | –ë–∏–Ω–∞—Ä–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è                                 | `torch.nn.BCELoss()`           | –°–∏–≥–º–æ–∏–¥–∞  | `torch.nn.Sigmoid()` | 1 |
|2*| –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è       | –ë–∏–Ω–∞—Ä–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è __–±–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –Ω–µ–π—Ä–æ–Ω–∞__| `torch.nn.BCEWithLogitsLoss()` | ‚ûñ | ‚ûñ | 1 |
|3*| –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è | –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è                           | `torch.nn.CrossEntropyLoss()`  | ‚ûñ | ‚ûñ | –°–æ–≤–ø–∞–¥–∞–µ—Ç —Å —á–∏—Å–ª–æ–º –∫–ª–∞—Å—Å–æ–≤ |
|4| –†–µ–≥—Ä–µ—Å—Å–∏—è | –°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞                           | `torch.nn.MSELoss()`  | ‚ûñ | ‚ûñ | 1 |
''')

st.markdown('''

#### –°–ª—É—á–∞–π ‚Ññ 1
```python

model = nn.Sequential(
    nn.Linear(n, m),
    nn.Sigmoid(),
    nn.Dropout(),
    nn.Linear(m, 1),
    nn.Sigmoid()
)

predictions = model(X) # —á–∏—Å–ª–∞ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ [0; 1]

loss = torch.nn.BCELoss(predictions, target)
loss.backward()
```

#### –°–ª—É—á–∞–π ‚Ññ 2

–ß–∞—Å—Ç–æ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –≤ –∑–∞–¥–∞—á–µ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Å–∏–≥–º–æ–∏–¥–æ–π, —Ç–æ–≥–¥–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å `torch.nn.BCEWithLogitsLoss`, –æ–¥–Ω–∞–∫–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π __–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π__ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ –∫–ª–∞—Å—Å—É –≤—Å–µ —Ä–∞–≤–Ω–æ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å —Å–∏–≥–º–æ–∏–¥—É. 

```python


model = nn.Sequential(
    nn.Linear(n, m),
    nn.Sigmoid(),
    nn.Dropout(),
    nn.Linear(m, 1)
)

predictions = model(X) 
loss = torch.nn.BCEWithLogitsLoss(predictions, target)
loss.backward()

# –ø–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ –∫–ª–∞—Å—Å—É
probabilities = torch.functional.sigmoid(predictions) # —á–∏—Å–ª–∞ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ [0; 1]

```
#### –°–ª—É—á–∞–π ‚Ññ 3
–ü—Ä–∏ —Ä–µ—à–µ–Ω–∏–∏ –∑–∞–¥–∞—á–∏ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ—É–Ω–∫—Ü–∏—é —Å–æ—Ñ—Ç–º–∞–∫—Å–∞ –º—ã –ø—Ä–∏–º–µ–Ω—è–µ–º __—Ç–æ–ª—å–∫–æ__ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏. –í —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –º—ã –ø–µ—Ä–µ–¥–∞—ë–º ¬´—Å—ã—Ä—ã–µ¬ª –∑–Ω–∞—á–µ–Ω–∏—è —Å –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è (—Ç.–µ. –Ω–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ) ‚Äì __–ª–æ–≥–∏—Ç—ã__. –§—É–Ω–∫—Ü–∏—è `torch.nn.CrossEntropyLoss()` –æ–∂–∏–¥–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –∏–º–µ–Ω–Ω–æ –∏—Ö, –∞ –Ω–µ —á–∏—Å–ª–∞ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ $$[0; 1]$$. 


```python
# K - —á–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤
model = nn.Sequential(
    nn.Linear(n, m),
    nn.Sigmoid(),
    nn.Dropout(),
    nn.Linear(m, K)
)

predictions = model(X) # ‚¨ÖÔ∏è –ª–æ–≥–∏—Ç—ã ‚Äì –ª—é–±—ã–µ —á–∏—Å–ª–∞ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ [-‚àû; +‚àû]
loss = torch.nn.CrossEntropyLoss(predictions, target)
loss.backward()

# –ø–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ –∫–ª–∞—Å—Å—É
probabilities = torch.functional.softmax(predictions) # —á–∏—Å–ª–∞ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ [0; 1]

```
''')
